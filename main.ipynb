{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import LlamaCpp\n",
    "\n",
    "from prompt_factory import (\n",
    "    SYSTEM_GRAPH_GENERATOR_PROMPT,\n",
    "    GRAPH_GENERATOR_PROMPT,\n",
    "    SYSTEM_CODE_CORRECTOR_PROMPT,\n",
    "    CODE_CORRECTOR_PROMPT\n",
    ")\n",
    "from agents import LLMAgent\n",
    "from tester import TestModule\n",
    "from utils import try_correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scafartogregory/Desktop/idea_extraction/idea_extraction_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3490: UserWarning: WARNING! repeat_last_n is not default parameter.\n",
      "                repeat_last_n was transferred to model_kwargs.\n",
      "                Please confirm that repeat_last_n is what you intended.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "/Users/scafartogregory/Desktop/idea_extraction/idea_extraction_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3490: UserWarning: WARNING! best_of_n is not default parameter.\n",
      "                best_of_n was transferred to model_kwargs.\n",
      "                Please confirm that best_of_n is what you intended.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "llm  = LlamaCpp(model_path = \"models/cpp_models/llama_3.1_FP16.gguf\",n_ctx=2048,max_tokens= 2000 ,repeat_last_n=20,stop=[\"END CODE\"],top_k=3,n_gpu_layers=33,best_of_n=2,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Code_Generator_Agent = LLMAgent(llm, SYSTEM_GRAPH_GENERATOR_PROMPT,GRAPH_GENERATOR_PROMPT)\n",
    "Code_Corrector_Agent = LLMAgent(llm, SYSTEM_CODE_CORRECTOR_PROMPT,CODE_CORRECTOR_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g9/w9q193415dqd_3g5fx11gt_40000gn/T/ipykernel_15204/3454204520.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  'Start Date': pd.date_range('2020-01-01', periods=n, freq='M')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "n=10\n",
    "data = {\n",
    "    'ID': np.arange(1, n+1),\n",
    "    'Name': [f'Employee_{i}' for i in range(1, n+1)],\n",
    "    'Age': np.random.randint(22, 65, size=n),\n",
    "    'Salary': np.random.randint(35000, 120000, size=n),\n",
    "    'Department': np.random.choice(['IT', 'HR', 'Finance', 'Marketing'], size=n),\n",
    "    'Start Date': pd.date_range('2020-01-01', periods=n, freq='M')\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Code_Generator_Agent(\n",
    "    {\n",
    "       \"dataframe\":  df,\n",
    "       \"graph\" : \"bar chart\"\n",
    "        \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester =  TestModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tester.exec_code(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if output[\"return_code\"] == 1 :\n",
    "    try_correction(Code_Corrector_Agent,tester=tester,output=output,nb_try=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec /opt/homebrew/bin/python3.12 nécessitent le package ipykernel.\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\u001b[1;31mCommande : '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "{\n",
    "        \"ID\": list(np.arange(1, n + 1)),\n",
    "        \"Name\": [f\"Employee_{i}\" for i in range(1, n + 1)],\n",
    "        \"Age\": list(np.random.randint(22, 65, size=n)),\n",
    "        \"Salary\": list(np.random.randint(35000, 120000, size=n)),\n",
    "        \"Department\": list(np.random.choice([\"IT\", \"HR\", \"Finance\", \"Marketing\"], size=n)),\n",
    "        \"Start Date\": list(pd.date_range(\"2020-01-01\", periods=n, freq=\"M\")),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idea_extraction_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
